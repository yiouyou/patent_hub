import asyncio
import json
import logging
import os
import tempfile
from typing import Any

import frappe
import httpx
from frappe import enqueue
from frappe.utils import now_datetime

from patent_hub.api._utils import (
	complete_task_fields,
	fail_task_fields,
	init_task_fields,
	restore_from_json_serializable,
	text_to_base64,
	universal_decompress,
)

logger = frappe.logger("app.patent_hub.patent_wf.call_align2tex2docx")
logger.setLevel(logging.INFO)

TIMEOUT = 1800


@frappe.whitelist()
def run(docname: str, force: bool = False):
	try:
		logger.info(f"[Align2Tex2Docx] å‡†å¤‡å¯åŠ¨ä»»åŠ¡: {docname}, force={force}")

		# ğŸ”§ æ·»åŠ æƒé™æ£€æŸ¥
		doc = frappe.get_doc("Patent Workflow", docname)
		doc.check_permission("write")

		if doc.is_done_align2tex2docx and not force:
			logger.warning(f"[Align2Tex2Docx] ä»»åŠ¡å·²å®Œæˆï¼Œæœªå¼ºåˆ¶é‡è·‘: {docname}")
			return {"success": True, "message": "ä»»åŠ¡å·²å®Œæˆï¼Œæœªé‡å¤æ‰§è¡Œ"}

		if doc.is_running_align2tex2docx:
			return {"success": False, "error": "ä»»åŠ¡æ­£åœ¨è¿è¡Œä¸­ï¼Œè¯·ç­‰å¾…å®Œæˆ"}

		# ğŸ”§ ä½¿ç”¨æ•°æ®åº“äº‹åŠ¡ç¡®ä¿çŠ¶æ€ä¸€è‡´æ€§
		frappe.db.begin()
		try:
			init_task_fields(doc, "align2tex2docx", "A2T2D", logger)
			doc.save(ignore_permissions=True, ignore_version=True)
			frappe.db.commit()
		except Exception:
			frappe.db.rollback()
			raise

		# ğŸ”§ ä½¿ç”¨æ›´å…·ä½“çš„é˜Ÿåˆ—åç§°å’Œjobname
		job = enqueue(
			"patent_hub.api.call_align2tex2docx._job",
			queue="long",
			timeout=TIMEOUT,
			job_name=f"align2tex2docx_{docname}",  # å”¯ä¸€çš„jobåç§°
			docname=docname,
			user=frappe.session.user,
		)

		logger.info(f"[Align2Tex2Docx] å·²å…¥é˜Ÿ: {docname}, job_id: {job.id}")
		return {"success": True, "message": "ä»»åŠ¡å·²æäº¤æ‰§è¡Œé˜Ÿåˆ—", "job_id": job.id}

	except frappe.PermissionError:
		return {"success": False, "error": "æƒé™ä¸è¶³"}
	except Exception as e:
		logger.error(f"[Align2Tex2Docx] å¯åŠ¨ä»»åŠ¡å¤±è´¥: {e}")
		logger.error(frappe.get_traceback())
		return {"success": False, "error": f"å¯åŠ¨ä»»åŠ¡å¤±è´¥: {e!s}"}


async def call_chain_with_retry(url: str, payload: dict, max_retries: int = 5) -> dict[str, Any]:
	"""ä¼˜åŒ–çš„å¸¦é‡è¯•æœºåˆ¶çš„APIè°ƒç”¨"""

	# ğŸ”§ ä¼˜åŒ–è¶…æ—¶é…ç½®
	timeout = httpx.Timeout(
		connect=10.0,
		read=300.0,  # 5åˆ†é’Ÿè¯»å–è¶…æ—¶
		write=30.0,
		pool=30.0,
	)

	limits = httpx.Limits(max_keepalive_connections=5, max_connections=10, keepalive_expiry=30.0)

	# ğŸ”§ æŒ‡æ•°é€€é¿ç­–ç•¥
	backoff_factor = 2

	for attempt in range(max_retries):
		try:
			async with httpx.AsyncClient(
				timeout=timeout,
				limits=limits,
				http2=False,
				# ğŸ”§ æ·»åŠ é‡è¯•ç›¸å…³çš„headers
				headers={
					"User-Agent": "PatentHub/1.0",
					"Accept": "application/json",
					"Content-Type": "application/json",
				},
			) as client:
				logger.info(f"APIè°ƒç”¨å°è¯• {attempt + 1}/{max_retries}")
				response = await client.post(url, json=payload)

				if response.status_code == 200:
					result = response.json()
					logger.info(f"APIè°ƒç”¨æˆåŠŸï¼Œå“åº”å¤§å°: {len(response.content)} å­—èŠ‚")
					return result

				# ğŸ”§ åŒºåˆ†ä¸åŒçš„HTTPé”™è¯¯
				elif response.status_code >= 500:
					# æœåŠ¡å™¨é”™è¯¯ï¼Œå¯ä»¥é‡è¯•
					logger.warning(f"æœåŠ¡å™¨é”™è¯¯ {response.status_code}ï¼Œå°†é‡è¯•")
					if attempt == max_retries - 1:
						raise httpx.HTTPStatusError(
							message=f"HTTP {response.status_code}: {response.text}",
							request=response.request,
							response=response,
						)
				else:
					# å®¢æˆ·ç«¯é”™è¯¯ï¼Œä¸é‡è¯•
					raise httpx.HTTPStatusError(
						message=f"HTTP {response.status_code}: {response.text}",
						request=response.request,
						response=response,
					)

		except (httpx.RemoteProtocolError, httpx.ReadTimeout, httpx.ConnectTimeout) as e:
			logger.warning(f"ç½‘ç»œé”™è¯¯ (å°è¯• {attempt + 1}): {e}")
			if attempt == max_retries - 1:
				raise

		except httpx.HTTPStatusError as e:
			if e.response.status_code < 500:
				# å®¢æˆ·ç«¯é”™è¯¯ä¸é‡è¯•
				raise
			logger.warning(f"æœåŠ¡å™¨é”™è¯¯ (å°è¯• {attempt + 1}): {e}")
			if attempt == max_retries - 1:
				raise

		# ğŸ”§ æŒ‡æ•°é€€é¿
		if attempt < max_retries - 1:
			wait_time = backoff_factor**attempt
			logger.info(f"ç­‰å¾… {wait_time} ç§’åé‡è¯•...")
			await asyncio.sleep(wait_time)

	raise Exception("æ‰€æœ‰é‡è¯•éƒ½å¤±è´¥äº†")


def _job(docname: str, user=None):
	"""ä¼˜åŒ–çš„ä»»åŠ¡æ‰§è¡Œå‡½æ•°"""
	logger.info(f"[Align2Tex2Docx] å¼€å§‹æ‰§è¡Œä»»åŠ¡: {docname}")
	doc = None

	try:
		# ğŸ”§ ä½¿ç”¨ frappe.get_doc çš„ for_update å‚æ•°é¿å…å¹¶å‘é—®é¢˜
		doc = frappe.get_doc("Patent Workflow", docname, for_update=True)

		# é˜²å¾¡æ€§æ£€æŸ¥
		if not doc.is_running_align2tex2docx:
			logger.warning(f"[Align2Tex2Docx] ä»»åŠ¡å·²éè¿è¡ŒçŠ¶æ€ï¼Œè·³è¿‡æ‰§è¡Œ: {docname}")
			return

		# ğŸ”§ ä½¿ç”¨ frappe.get_cached_doc è·å–å•ä¾‹æ–‡æ¡£
		api_endpoint = frappe.get_cached_doc("API Endpoint", "API Endpoint")

		base_url = api_endpoint.server_ip_port.rstrip("/")
		app_name = api_endpoint.align2tex2docx.strip("/")
		url = f"{base_url}/{app_name}/invoke"

		tmp_folder = os.path.join(api_endpoint.get_password("server_work_dir"), doc.align2tex2docx_id)

		payload = {
			"input": {
				"patent_title": doc.patent_title,
				"base64file": text_to_base64(doc.application),
				"tmp_folder": tmp_folder,
			}
		}

		# è°ƒç”¨API
		result = asyncio.run(call_chain_with_retry(url, payload))

		# ğŸ”§ é‡æ–°è·å–æ–‡æ¡£ç¡®ä¿æ•°æ®æœ€æ–°
		doc.reload()

		# å†æ¬¡æ£€æŸ¥ä»»åŠ¡çŠ¶æ€
		if not doc.is_running_align2tex2docx:
			logger.warning(f"[Align2Tex2Docx] ä»»åŠ¡åœ¨æ‰§è¡Œè¿‡ç¨‹ä¸­è¢«å–æ¶ˆ: {docname}")
			return

		# è§£æå“åº”
		output = result.get("output")
		if not output:
			raise ValueError("APIå“åº”æ ¼å¼é”™è¯¯ï¼šç¼ºå°‘outputå­—æ®µ")

		if isinstance(output, str):
			output = json.loads(output)

		_res = universal_decompress(output.get("res", ""), as_json=True)

		# ğŸ”§ æ‰¹é‡æ›´æ–°å­—æ®µï¼Œå‡å°‘æ•°æ®åº“æ“ä½œ
		update_fields = {
			"application_align": _res.get("application_align"),
			"application_tex": _res.get("application_tex"),
			"before_tex": _res.get("application_align"),
			"figure_codes": "\n==========\n".join([str(code) for code in _res.get("figure_codes", [])]),
		}

		# å¤„ç†DOCXæ–‡ä»¶
		application_docx_bytes = _res.get("application_docx_bytes")
		if application_docx_bytes:
			if isinstance(application_docx_bytes, dict):
				application_docx_bytes = restore_from_json_serializable(application_docx_bytes)

			if not isinstance(application_docx_bytes, bytes):
				raise ValueError(f"DOCXæ•°æ®ç±»å‹é”™è¯¯ï¼ŒæœŸæœ›bytesï¼Œå®é™…: {type(application_docx_bytes)}")

			# ä¿å­˜æ–‡ä»¶
			file_doc = save_docx_file(doc, application_docx_bytes)
			update_fields["application_docx_link"] = file_doc.name

		# ğŸ”§ ä½¿ç”¨ frappe.db.set_value æ‰¹é‡æ›´æ–°
		for field, value in update_fields.items():
			if value is not None:
				doc.set(field, value)

		# å®Œæˆä»»åŠ¡
		complete_task_fields(
			doc,
			"align2tex2docx",
			extra_fields={
				"time_s_align2tex2docx": output.get("TIME(s)", 0.0),
				"cost_align2tex2docx": output.get("cost", 0),
			},
		)

		# ğŸ”§ ä½¿ç”¨ ignore_permissions å’Œ ignore_version ä¼˜åŒ–ä¿å­˜
		doc.save(ignore_permissions=True, ignore_version=True)
		frappe.db.commit()

		logger.info(f"[Align2Tex2Docx] æ‰§è¡ŒæˆåŠŸ: {docname}")

		# ğŸ”§ ä½¿ç”¨æ›´å…·ä½“çš„äº‹ä»¶åç§°
		frappe.publish_realtime(
			"patent_workflow_update",
			{"docname": doc.name, "event": "align2tex2docx_done", "message": "Align2Tex2Docx ä»»åŠ¡å®Œæˆ"},
			user=user,
		)

	except Exception as e:
		logger.error(f"[Align2Tex2Docx] æ‰§è¡Œå¤±è´¥: {e}")
		logger.error(frappe.get_traceback())

		if doc:
			try:
				doc.reload()  # é‡æ–°åŠ è½½ä»¥è·å–æœ€æ–°çŠ¶æ€
				fail_task_fields(doc, "align2tex2docx", str(e))
				doc.save(ignore_permissions=True, ignore_version=True)
				frappe.db.commit()
			except Exception as save_error:
				logger.error(f"ä¿å­˜å¤±è´¥çŠ¶æ€æ—¶å‡ºé”™: {save_error}")

			frappe.publish_realtime(
				"patent_workflow_update",
				{"docname": docname, "event": "align2tex2docx_failed", "error": str(e)},
				user=user,
			)


def save_docx_file(doc, docx_bytes):
	import re

	from frappe.utils.file_manager import save_file

	if not isinstance(docx_bytes, bytes):
		raise ValueError(f"å‚æ•°å¿…é¡»æ˜¯bytesç±»å‹ï¼Œå®é™…ç±»å‹: {type(docx_bytes)}")

	base_filename = f"{doc.align2tex2docx_id}_application_"

	try:
		# ğŸ”§ è·å–æ‰€æœ‰ç›¸å…³çš„æ–‡ä»¶
		all_files = frappe.get_all(
			"File",
			filters={
				"attached_to_doctype": doc.doctype,
				"attached_to_name": doc.name,
			},
			fields=["name", "file_name", "file_url"],
		)
		logger.info(f"all_files: {all_files}")

		# ğŸ”§ ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼ç²¾ç¡®åŒ¹é…
		pattern = re.compile(rf"^{re.escape(doc.align2tex2docx_id)}.*\.docx$")
		files_to_delete = [f for f in all_files if f.file_name and pattern.match(f.file_name)]
		logger.info(f"æ‰¾åˆ°éœ€è¦åˆ é™¤çš„æ–‡ä»¶: {[f.file_name for f in files_to_delete]}")

		# åˆ é™¤åŒ¹é…çš„æ–‡ä»¶
		for file_to_delete in files_to_delete:
			try:
				frappe.delete_doc("File", file_to_delete.name, force=True, ignore_permissions=True)
				logger.info(f"åˆ é™¤æ—§æ–‡ä»¶: {file_to_delete.file_name}")
			except Exception as e:
				logger.warning(f"åˆ é™¤æ—§æ–‡ä»¶å¤±è´¥ {file_to_delete.name}: {e}")

		if files_to_delete:
			frappe.db.commit()
			# ç­‰å¾…ä¸€å°æ®µæ—¶é—´ç¡®ä¿åˆ é™¤æ“ä½œå®Œæˆ
			import time

			time.sleep(0.1)

	except Exception as e:
		logger.info(f"æ¸…ç†æ—§æ–‡ä»¶æ—¶å‡ºé”™: {e}")

	# ç”Ÿæˆæœ€ç»ˆæ–‡ä»¶å
	final_filename = f"{base_filename}.docx"

	try:
		logger.info(f"ä¿å­˜æ–‡ä»¶ {final_filename}ï¼Œå¤§å°: {len(docx_bytes)} å­—èŠ‚")

		file_doc = save_file(
			fname=final_filename, content=docx_bytes, dt=doc.doctype, dn=doc.name, is_private=1, decode=False
		)

		logger.info(f"æ–‡ä»¶ä¿å­˜æˆåŠŸ: {file_doc.name}")
		return file_doc

	except Exception as e:
		logger.error(f"ä¿å­˜DOCXæ–‡ä»¶å¤±è´¥: {e}")
		raise
