# ===============================================
# ğŸ“¦ å·¥å…·æ¨¡å—ï¼špatent_hub.api._utils
# æè¿°ï¼šæä¾›é€šç”¨ä»»åŠ¡å·¥å…·å‡½æ•°ï¼ŒåŒ…æ‹¬ï¼š
#  - å­—ç¬¦ä¸²å‹ç¼©/è§£å‹
#  - JSON å‹ç¼©/è§£å‹
#  - æ–‡ä»¶å‹ç¼©/è§£å‹
#  - ID ç”Ÿæˆ
#  - å¡æ­»ä»»åŠ¡æ£€æµ‹ä¸é‡ç½®ï¼ˆå¿ƒè·³æœºåˆ¶ï¼‰
#  - é€šç”¨ä»»åŠ¡çŠ¶æ€é‡ç½®
#  - å¿ƒè·³è£…é¥°å™¨ï¼ˆè‡ªåŠ¨å¿ƒè·³æ›´æ–°ï¼‰
# ===============================================

import base64
import gzip
import json
import logging
import os
import pickle
import threading
from functools import wraps
from typing import Any

import frappe
from frappe.model.naming import make_autoname
from frappe.utils import now_datetime, time_diff_in_seconds

# æ—¥å¿—è®¾ç½®
logger = frappe.logger("app.patent_hub.patent_wf._util")
# logger.setLevel(logging.DEBUG)


# ---------------------------------------------------
# ğŸ”¹ æ–‡æœ¬å‹ç¼©ä¸è§£å‹ï¼ˆå­—ç¬¦ä¸² â‡„ base64ï¼‰
# ---------------------------------------------------


def make_json_serializable(obj: Any) -> Any:
	"""
	å°†ä»»æ„å¯¹è±¡è½¬æ¢ä¸ºJSONå¯åºåˆ—åŒ–çš„æ ¼å¼
	"""
	if obj is None or isinstance(obj, (str, int, float, bool)):
		return obj
	elif isinstance(obj, bytes):
		# bytes è½¬ä¸ºç‰¹æ®Šæ ‡è®°çš„å­—å…¸
		return {"__type__": "bytes", "__data__": base64.b64encode(obj).decode("ascii")}
	elif isinstance(obj, dict):
		return {str(k): make_json_serializable(v) for k, v in obj.items()}
	elif isinstance(obj, (list, tuple)):
		result = [make_json_serializable(item) for item in obj]
		if isinstance(obj, tuple):
			# ä¿ç•™ tuple ç±»å‹ä¿¡æ¯
			return {"__type__": "tuple", "__data__": result}
		return result
	elif hasattr(obj, "__dict__"):
		# å¤„ç†è‡ªå®šä¹‰å¯¹è±¡
		return {
			"__type__": "object",
			"__class__": obj.__class__.__name__,
			"__data__": make_json_serializable(obj.__dict__),
		}
	else:
		# å…¶ä»–ç±»å‹è½¬ä¸ºå­—ç¬¦ä¸²
		return {"__type__": "str_repr", "__data__": str(obj)}


def restore_from_json_serializable(obj: Any) -> Any:
	"""
	è¿˜åŸ JSON åºåˆ—åŒ–æ—¶è½¬æ¢çš„ç‰¹æ®Šç±»å‹
	"""
	if isinstance(obj, dict):
		if "__type__" in obj:
			if obj["__type__"] == "bytes":
				return base64.b64decode(obj["__data__"].encode("ascii"))
			elif obj["__type__"] == "tuple":
				return tuple(restore_from_json_serializable(item) for item in obj["__data__"])
			elif obj["__type__"] == "str_repr":
				return obj["__data__"]  # ä¿æŒä¸ºå­—ç¬¦ä¸²
			elif obj["__type__"] == "object":
				# ç®€å•è¿”å›æ•°æ®éƒ¨åˆ†ï¼Œä¸é‡å»ºå¯¹è±¡
				return restore_from_json_serializable(obj["__data__"])
		else:
			return {k: restore_from_json_serializable(v) for k, v in obj.items()}
	elif isinstance(obj, list):
		return [restore_from_json_serializable(item) for item in obj]
	else:
		return obj


def universal_compress(data: Any) -> str:
	"""
	é€šç”¨å‹ç¼©å‡½æ•°
	æ•°æ®æµ: ä»»æ„æ•°æ® â†’ å­—èŠ‚ â†’ gzipå‹ç¼© â†’ base64ç¼–ç  â†’ å­—ç¬¦ä¸²
	æ”¯æŒæ··åˆç±»å‹çš„å­—å…¸å’Œåˆ—è¡¨
	"""
	# æ­¥éª¤1: è½¬ä¸ºå­—èŠ‚
	if isinstance(data, bytes):
		raw_bytes = data
	elif isinstance(data, str):
		raw_bytes = data.encode("utf-8")
	elif isinstance(data, (dict, list, tuple, int, float, bool)) or data is None:
		try:
			converted_data = make_json_serializable(data)
			json_str = json.dumps(converted_data, ensure_ascii=False, separators=(",", ":"))
			raw_bytes = json_str.encode("utf-8")
		except (TypeError, ValueError):
			# å¦‚æœ JSON åºåˆ—åŒ–ä»ç„¶å¤±è´¥ï¼Œä½¿ç”¨ pickle ä½œä¸ºåå¤‡æ–¹æ¡ˆ
			raw_bytes = pickle.dumps(data)
	else:
		# å¯¹äºå…¶ä»–å¤æ‚ç±»å‹ï¼Œç›´æ¥ä½¿ç”¨ pickle
		raw_bytes = pickle.dumps(data)
	# æ­¥éª¤2: gzipå‹ç¼©
	compressed = gzip.compress(raw_bytes)
	# æ­¥éª¤3: base64ç¼–ç 
	return base64.b64encode(compressed).decode("ascii")


def universal_decompress(compressed_str: str, as_json: bool = False) -> Any:
	"""
	é€šç”¨è§£å‹ç¼©å‡½æ•°
	"""
	try:
		# æ­¥éª¤1: base64è§£ç 
		compressed_bytes = base64.b64decode(compressed_str.encode("ascii"))
		# æ­¥éª¤2: gzipè§£å‹ç¼©
		raw_bytes = gzip.decompress(compressed_bytes)
		if as_json:
			# å°è¯• JSON è§£æ
			try:
				json_str = raw_bytes.decode("utf-8")
				data = json.loads(json_str)
				# è¿˜åŸç‰¹æ®Šç±»å‹
				return restore_from_json_serializable(data)
			except (json.JSONDecodeError, UnicodeDecodeError):
				# JSON è§£æå¤±è´¥ï¼Œä½¿ç”¨ pickle
				return pickle.loads(raw_bytes)
		else:
			# å°è¯•å­—ç¬¦ä¸²è§£ç 
			try:
				return raw_bytes.decode("utf-8")
			except UnicodeDecodeError:
				# ä¸æ˜¯æ–‡æœ¬ï¼Œä½¿ç”¨ pickle
				return pickle.loads(raw_bytes)
	except Exception as e:
		raise ValueError(f"è§£å‹ç¼©å¤±è´¥: {e}")


def text_to_base64(text: str) -> str:
	"""æ–‡æœ¬å­—ç¬¦ä¸²è½¬base64"""
	return base64.b64encode(text.encode("utf-8")).decode("ascii")


def get_attached_files(doc, table_field: str) -> list[dict]:
	"""
	ä»æŒ‡å®šå­è¡¨å­—æ®µä¸­è¯»å– file å­—æ®µï¼Œè½¬æ¢ä¸º base64 å‹ç¼©å­—ç¬¦ä¸²ã€‚
	è¿”å›æ ¼å¼ï¼š[{ file_path: ..., base64: ..., original_filename: ..., note: ... }, ...]
	"""
	results = []
	table = getattr(doc, table_field, [])
	for row in table:
		file_url = row.file
		if not file_url:
			continue
		# åˆ¤æ–­è·¯å¾„ä½ç½®ï¼ˆprivate/publicï¼‰
		if file_url.startswith("/private/files/"):
			filename = file_url.replace("/private/files/", "")
			file_path = os.path.join(frappe.get_site_path("private", "files"), filename)
		elif file_url.startswith("/files/"):
			filename = file_url.replace("/files/", "")
			file_path = os.path.join(frappe.get_site_path("public", "files"), filename)
		else:
			frappe.throw(f"æœªçŸ¥æ–‡ä»¶è·¯å¾„æ ¼å¼: {file_url}")
		if not os.path.exists(file_path):
			frappe.throw(f"æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
		# è·å–åŸå§‹æ–‡ä»¶åï¼ˆåŒ…å«æ‰©å±•åï¼‰
		original_filename = os.path.basename(filename)
		with open(file_path, "rb") as f:
			file_data = f.read()
		results.append(
			{
				"content_bytes": file_data,
				"original_filename": original_filename,
				# "file_path": file_path,
				# "note": row.note,
			}
		)
	return results


# ---------------------------------------------------
# ğŸ”¹ ç”Ÿæˆæ­¥éª¤å”¯ä¸€ IDï¼ˆåŸºäº patent_id å’Œå‰ç¼€ï¼‰
# ---------------------------------------------------


def generate_step_id(patent_id: str, prefix: str) -> str:
	"""
	ä½¿ç”¨ Frappe çš„ make_autoname ç”Ÿæˆï¼š
	æ ¼å¼ï¼š{patent_id}-{prefix}-001
	"""
	return make_autoname(f"{patent_id}-{prefix}-.#")


# ---------------------------------------------------
# ğŸ”¹ å¿ƒè·³æœºåˆ¶é…ç½®å’Œè¶…æ—¶æ£€æµ‹ï¼ˆä¼˜åŒ–ç‰ˆï¼‰
# ---------------------------------------------------

# è¶…æ—¶æ—¶é—´ï¼š5åˆ†é’Ÿ - å¿«é€Ÿæ•…éšœæ£€æµ‹
TASK_TIMEOUTS = {
	"title2scene": 300,  # 5åˆ†é’Ÿ
	"info2tech": 300,  # 5åˆ†é’Ÿ
	"scene2tech": 300,  # 5åˆ†é’Ÿ
	"tech2application": 300,  # 5åˆ†é’Ÿ
	"review2revise": 300,  # 5åˆ†é’Ÿ
	"align2tex2docx": 300,  # 5åˆ†é’Ÿ
}

# å¿ƒè·³é—´éš”ï¼š1åˆ†40ç§’ - é¢‘ç¹ä½†ä¸è¿‡åº¦
HEARTBEAT_INTERVAL = 100


def update_task_heartbeat(doc, task_key: str):
	"""
	æ›´æ–°ä»»åŠ¡å¿ƒè·³æ—¶é—´ï¼Œé˜²æ­¢è¢«è¯¯åˆ¤ä¸ºè¶…æ—¶
	:param doc: æ–‡æ¡£å¯¹è±¡
	:param task_key: ä»»åŠ¡å­—æ®µå‰ç¼€
	"""
	heartbeat_field = f"{task_key}_last_heartbeat"
	current_time = now_datetime()
	setattr(doc, heartbeat_field, current_time)
	doc.save()
	logger.debug(f"[{task_key}] å¿ƒè·³æ›´æ–°: {doc.doctype}.{doc.name} at {current_time}")


def detect_and_reset_stuck_task(task_key: str, label: str, doctype: str, timeout_seconds=None):
	"""
	åŸºäºå¿ƒè·³æœºåˆ¶çš„ä»»åŠ¡è¶…æ—¶æ£€æµ‹ï¼Œèƒ½å¿«é€Ÿå‘ç°çœŸæ­£å¡æ­»çš„ä»»åŠ¡
	:param task_key: ä»»åŠ¡å­—æ®µå‰ç¼€ï¼ˆå¦‚ align2tex2docxï¼‰
	:param label: ä¸­æ–‡ä»»åŠ¡åç§°ï¼ˆç”¨äºæ—¥å¿—å’Œè¯„è®ºï¼‰
	:param doctype: æ–‡æ¡£ç±»å‹åç§°ï¼ˆå¦‚ "Patent Workflow"ï¼‰
	:param timeout_seconds: å¿ƒè·³è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨TASK_TIMEOUTSä¸­çš„é…ç½®
	"""
	# ä½¿ç”¨ä¼˜åŒ–åçš„çŸ­è¶…æ—¶æ—¶é—´
	if timeout_seconds is None:
		timeout_seconds = TASK_TIMEOUTS.get(task_key, 300)  # é»˜è®¤5åˆ†é’Ÿ

	started_at_field = f"{task_key}_started_at"
	heartbeat_field = f"{task_key}_last_heartbeat"
	is_running_field = f"is_running_{task_key}"
	is_done_field = f"is_done_{task_key}"
	run_count_field = f"run_count_{task_key}"
	status_field = f"status_{task_key}"

	stuck_docs = frappe.get_all(
		doctype,  # ğŸ”¥ ä½¿ç”¨å‚æ•°åŒ–çš„doctype
		filters={is_running_field: 1, is_done_field: 0},
		fields=["name", started_at_field, heartbeat_field, run_count_field],
	)

	for doc in stuck_docs:
		if doc.get(run_count_field, 0) == 0:
			logger.info(f"[{label}] è·³è¿‡æœªå¯åŠ¨çš„ä»»åŠ¡: {doctype}.{doc.name}")
			continue

		# ä¼˜å…ˆæ£€æŸ¥å¿ƒè·³æ—¶é—´ï¼Œå¦‚æœæ²¡æœ‰å¿ƒè·³åˆ™ä½¿ç”¨å¼€å§‹æ—¶é—´
		check_time = doc.get(heartbeat_field) or doc.get(started_at_field)
		if not check_time:
			logger.warning(f"[{label}] ä»»åŠ¡ç¼ºå°‘æ—¶é—´æˆ³: {doctype}.{doc.name}")
			continue

		delta = time_diff_in_seconds(now_datetime(), check_time)
		if delta > timeout_seconds:
			_doc = frappe.get_doc(doctype, doc.name)
			setattr(_doc, is_running_field, 0)
			setattr(_doc, status_field, "Failed")

			# åŒºåˆ†æ˜¯å¿ƒè·³è¶…æ—¶è¿˜æ˜¯å¯åŠ¨è¶…æ—¶
			timeout_type = "å¿ƒè·³" if doc.get(heartbeat_field) else "å¯åŠ¨"

			_doc.append(
				"comments",
				{
					"comment_type": "Comment",
					"content": f"âš ï¸ è‡ªåŠ¨æ£€æµ‹ï¼š{label} {timeout_type}è¶…æ—¶ï¼ˆ{delta}s > {timeout_seconds}sï¼‰ï¼Œä»»åŠ¡å¯èƒ½å·²å¡æ­»ï¼ŒçŠ¶æ€å·²é‡ç½®ä¸º Failedã€‚å»ºè®®å¿ƒè·³é—´éš”: {HEARTBEAT_INTERVAL}s",
				},
			)
			_doc.save()
			logger.warning(
				f"[{label}] ä»»åŠ¡{timeout_type}è¶…æ—¶è‡ªåŠ¨é‡ç½®: {doctype}.{_doc.name}, è¶…æ—¶: {delta}s > {timeout_seconds}s"
			)


# ---------------------------------------------------
# ğŸ”¹ å¿ƒè·³è£…é¥°å™¨ï¼ˆè‡ªåŠ¨å¿ƒè·³æ›´æ–°ï¼‰
# ---------------------------------------------------


def with_heartbeat(task_key: str, doctype: str, heartbeat_interval: int = None):
	"""
	è£…é¥°å™¨ï¼šä¸ºé•¿æ—¶é—´è¿è¡Œçš„å‡½æ•°è‡ªåŠ¨æ·»åŠ å¿ƒè·³æ›´æ–°
	:param task_key: ä»»åŠ¡é”®åï¼ˆå¦‚ "title2scene"ï¼‰
	:param doctype: æ–‡æ¡£ç±»å‹åç§°ï¼ˆå¦‚ "Patent Workflow"ï¼‰
	:param heartbeat_interval: å¿ƒè·³é—´éš”ï¼ˆç§’ï¼‰ï¼Œé»˜è®¤ä½¿ç”¨ HEARTBEAT_INTERVAL

	ä½¿ç”¨ç¤ºä¾‹ï¼š
	@frappe.whitelist()
	@with_heartbeat("title2scene", "Patent Workflow")
	def run(docname, force=False):
	    pass
	"""
	if heartbeat_interval is None:
		heartbeat_interval = HEARTBEAT_INTERVAL

	def decorator(func):
		@wraps(func)
		def wrapper(docname, *args, **kwargs):
			doc = frappe.get_doc(doctype, docname)
			heartbeat_stop_event = threading.Event()
			heartbeat_thread = None

			def heartbeat_worker():
				"""å¿ƒè·³æ›´æ–°å·¥ä½œçº¿ç¨‹"""
				logger.info(f"[{task_key}] å¿ƒè·³çº¿ç¨‹å¯åŠ¨: {doctype}.{docname}, é—´éš”: {heartbeat_interval}s")

				while not heartbeat_stop_event.wait(heartbeat_interval):
					try:
						# é‡æ–°è·å–æ–‡æ¡£ï¼Œæ£€æŸ¥ä»»åŠ¡æ˜¯å¦è¿˜åœ¨è¿è¡Œ
						current_doc = frappe.get_doc(doctype, docname)
						is_running_field = f"is_running_{task_key}"

						if not getattr(current_doc, is_running_field, 0):
							logger.info(f"[{task_key}] ä»»åŠ¡å·²åœæ­¢ï¼Œå¿ƒè·³çº¿ç¨‹é€€å‡º: {doctype}.{docname}")
							break

						# æ›´æ–°å¿ƒè·³
						update_task_heartbeat(current_doc, task_key)
						frappe.db.commit()
						logger.debug(f"[{task_key}] å¿ƒè·³æ›´æ–°æˆåŠŸ: {doctype}.{docname}")

					except Exception as e:
						logger.error(f"[{task_key}] å¿ƒè·³æ›´æ–°å¤±è´¥: {doctype}.{docname}, é”™è¯¯: {e}")
						# å¿ƒè·³å¤±è´¥ä¸åº”è¯¥ä¸­æ–­ä¸»ä»»åŠ¡ï¼Œç»§ç»­å°è¯•

			try:
				# å¯åŠ¨å¿ƒè·³çº¿ç¨‹
				heartbeat_thread = threading.Thread(target=heartbeat_worker, daemon=True)
				heartbeat_thread.start()
				logger.info(f"[{task_key}] å¼€å§‹æ‰§è¡Œä»»åŠ¡ï¼ˆå¸¦å¿ƒè·³ï¼‰: {doctype}.{docname}")

				# æ‰§è¡ŒåŸå‡½æ•°
				result = func(docname, *args, **kwargs)

				logger.info(f"[{task_key}] ä»»åŠ¡æ‰§è¡Œå®Œæˆ: {doctype}.{docname}")
				return result

			except Exception as e:
				logger.error(f"[{task_key}] ä»»åŠ¡æ‰§è¡Œå¤±è´¥: {doctype}.{docname}, é”™è¯¯: {e}")
				raise
			finally:
				# åœæ­¢å¿ƒè·³çº¿ç¨‹
				if heartbeat_thread and heartbeat_thread.is_alive():
					logger.info(f"[{task_key}] åœæ­¢å¿ƒè·³çº¿ç¨‹: {doctype}.{docname}")
					heartbeat_stop_event.set()
					heartbeat_thread.join(timeout=2)  # ç­‰å¾…æœ€å¤š2ç§’
					if heartbeat_thread.is_alive():
						logger.warning(f"[{task_key}] å¿ƒè·³çº¿ç¨‹æœªèƒ½æ­£å¸¸é€€å‡º: {doctype}.{docname}")

		return wrapper

	return decorator


# ---------------------------------------------------
# ğŸ”¹ æ‰¹é‡ä»»åŠ¡å­—æ®µæ˜ å°„ï¼ˆç»Ÿä¸€å¤„ç†å¤šä¸ªä»»åŠ¡ï¼‰
# ---------------------------------------------------

# æŒ‰ DocType åˆ†ç»„çš„ä»»åŠ¡é…ç½®
DOCTYPE_TASKS = {
	"Patent Workflow": [
		("title2scene", "Title2Scene"),
		("info2tech", "Info2Tech"),
		("scene2tech", "Scene2Tech"),
		("tech2application", "Tech2Application"),
		("review2revise", "Review2Revise"),
		("align2tex2docx", "Align2Tex2Docx"),
	],
	"Code2png": [
		("code2png", "Code2png"),
	],
	"Md2docx": [
		("md2docx", "Md2docx"),
	],
}


def detect_and_reset_all_stuck_tasks(doctype: str):
	"""
	æ‰¹é‡æ£€æµ‹æŒ‡å®š DocType çš„æ‰€æœ‰ä»»åŠ¡ï¼ŒåŸºäºå¿ƒè·³æœºåˆ¶å¿«é€Ÿå‘ç°å¡æ­»ä»»åŠ¡
	:param doctype: æ–‡æ¡£ç±»å‹åç§°ï¼ˆå¦‚ "Patent Workflow"ï¼‰
	"""
	if doctype not in DOCTYPE_TASKS:
		logger.warning(f"æœªæ‰¾åˆ° DocType '{doctype}' çš„ä»»åŠ¡é…ç½®")
		return
	tasks = DOCTYPE_TASKS[doctype]
	logger.info(f"å¼€å§‹æ£€æµ‹å¡æ­»ä»»åŠ¡ï¼ˆåŸºäºå¿ƒè·³æœºåˆ¶ï¼‰: {doctype}ï¼Œå…± {len(tasks)} ä¸ªä»»åŠ¡...")
	for key, label in tasks:
		detect_and_reset_stuck_task(key, label, doctype)
	logger.info(f"å¡æ­»ä»»åŠ¡æ£€æµ‹å®Œæˆ: {doctype}")


def detect_and_reset_all_stuck_tasks_multi():
	"""
	å¤š DocType çš„å®šæ—¶ä»»åŠ¡åŒ…è£…å‡½æ•°
	è‡ªåŠ¨æ£€æµ‹æ‰€æœ‰å·²é…ç½®çš„ DocType
	"""
	for doctype in DOCTYPE_TASKS.keys():
		try:
			detect_and_reset_all_stuck_tasks(doctype)
		except Exception as e:
			logger.error(f"æ£€æµ‹ {doctype} å¡æ­»ä»»åŠ¡å¤±è´¥: {e}")


# ---------------------------------------------------
# ğŸ”¹ task ç›¸å…³å·¥å…·ï¼ˆå¿ƒè·³æœºåˆ¶ä¼˜åŒ–ç‰ˆï¼‰
# ---------------------------------------------------


def init_task_fields(doc, task_key: str, prefix: str, logger=logger):
	"""
	åˆå§‹åŒ–ä»»åŠ¡çŠ¶æ€å­—æ®µï¼Œå¹¶ç”Ÿæˆ IDã€‚
	- è®¾ç½®ä¸º Running çŠ¶æ€
	- è‹¥é¦–æ¬¡è¿è¡Œï¼Œåˆ™ç”Ÿæˆ ID
	- ç´¯åŠ  run_count
	- åˆå§‹åŒ–å¿ƒè·³æ—¶é—´

	:param doc: æ–‡æ¡£å¯¹è±¡ï¼ˆä»»æ„DocTypeï¼‰
	:param task_key: ä»»åŠ¡é”®å
	:param prefix: IDå‰ç¼€
	:param logger: æ—¥å¿—å¯¹è±¡
	"""
	id_field = f"{task_key}_id"
	started_at_field = f"{task_key}_started_at"
	heartbeat_field = f"{task_key}_last_heartbeat"
	is_running_field = f"is_running_{task_key}"
	is_done_field = f"is_done_{task_key}"
	status_field = f"status_{task_key}"
	run_count_field = f"run_count_{task_key}"

	# æ¯æ¬¡ init éƒ½ç”Ÿæˆæ–°çš„ID
	# ğŸ”¥ ä¿®æ”¹ï¼šæ”¯æŒä¸åŒDocTypeçš„IDç”Ÿæˆ
	if hasattr(doc, "patent_id"):
		# Patent Workflow ä½¿ç”¨ patent_id
		setattr(doc, id_field, generate_step_id(doc.patent_id, prefix))
	else:
		# å…¶ä»–DocTypeä½¿ç”¨ name æˆ–è‡ªå®šä¹‰é€»è¾‘
		setattr(doc, id_field, generate_step_id(doc.name, prefix))

	# è®¾ç½®è¿è¡ŒçŠ¶æ€
	current_time = now_datetime()
	setattr(doc, is_running_field, 1)
	setattr(doc, is_done_field, 0)
	setattr(doc, status_field, "Running")
	setattr(doc, started_at_field, current_time)
	setattr(doc, heartbeat_field, current_time)  # åˆå§‹åŒ–å¿ƒè·³æ—¶é—´

	# ç´¯åŠ è¿è¡Œæ¬¡æ•°
	setattr(doc, run_count_field, getattr(doc, run_count_field, 0) + 1)

	# è·å–è¯¥ä»»åŠ¡çš„å¿ƒè·³è¶…æ—¶é…ç½®
	heartbeat_timeout = TASK_TIMEOUTS.get(task_key, 300)

	logger.info(
		f"[{task_key}] åˆå§‹åŒ–ä»»åŠ¡: {doc.doctype}.{doc.name}, id={getattr(doc, id_field)}, status=Running, "
		f"run_count={getattr(doc, run_count_field)}, å¿ƒè·³è¶…æ—¶={heartbeat_timeout}s, "
		f"å»ºè®®å¿ƒè·³é—´éš”={HEARTBEAT_INTERVAL}s"
	)


def complete_task_fields(doc, task_key: str, extra_fields: dict = None, logger=logger):
	"""
	ç»Ÿä¸€å®Œæˆä»»åŠ¡çŠ¶æ€è®¾ç½®ï¼Œå¹¶ç´¯åŠ è¿è¡ŒæˆåŠŸæ¬¡æ•°å’Œç´¯è®¡è€—æ—¶/æˆæœ¬ã€‚

	:param doc: æ–‡æ¡£å¯¹è±¡ï¼ˆä»»æ„DocTypeï¼‰
	:param task_key: ä»»åŠ¡é”®å
	:param extra_fields: é¢å¤–å­—æ®µ
	:param logger: æ—¥å¿—å¯¹è±¡
	"""
	is_running_field = f"is_running_{task_key}"
	is_done_field = f"is_done_{task_key}"
	status_field = f"status_{task_key}"
	error_field = f"last_{task_key}_error"
	heartbeat_field = f"{task_key}_last_heartbeat"

	setattr(doc, is_running_field, 0)
	setattr(doc, is_done_field, 1)
	setattr(doc, status_field, "Done")
	setattr(doc, error_field, "æˆåŠŸï¼")
	setattr(doc, heartbeat_field, now_datetime())  # æœ€åæ›´æ–°å¿ƒè·³æ—¶é—´

	success_count_field = f"success_count_{task_key}"
	_success_count = int(getattr(doc, success_count_field, 0) or 0)
	setattr(doc, success_count_field, _success_count + 1)

	if extra_fields:
		for key, value in extra_fields.items():
			setattr(doc, key, value)
			# ç´¯è®¡æˆæœ¬
			if key.startswith("cost_"):
				total_field = key.replace("cost_", "total_cost_")
				try:
					current_total = float(getattr(doc, total_field, 0) or 0)
					new_value = float(value or 0)
					setattr(doc, total_field, current_total + new_value)
				except (ValueError, TypeError) as e:
					logger.info(f"Error converting cost values: {e}")
					setattr(doc, total_field, float(value or 0))
			# ç´¯è®¡æ—¶é—´
			if key.startswith("time_s_"):
				total_field = key.replace("time_s_", "total_time_s_")
				try:
					current_total = float(getattr(doc, total_field, 0) or 0)
					new_value = float(value or 0)
					setattr(doc, total_field, current_total + new_value)
				except (ValueError, TypeError) as e:
					logger.info(f"Error converting time values: {e}")
					setattr(doc, total_field, float(value or 0))

	doc.save()
	logger.info(
		f"[{task_key}] ä»»åŠ¡å®Œæˆ: {doc.doctype}.{doc.name}, status=Done, success_count={getattr(doc, success_count_field)}"
	)


def fail_task_fields(doc, task_key: str, error: str = None, logger=logger):
	"""
	è®¾ç½®ä»»åŠ¡å¤±è´¥çŠ¶æ€ï¼Œå¹¶è®°å½•é”™è¯¯ä¿¡æ¯ï¼ˆä¸å¢åŠ  success_countï¼‰

	:param doc: æ–‡æ¡£å¯¹è±¡ï¼ˆä»»æ„DocTypeï¼‰
	:param task_key: ä»»åŠ¡é”®å
	:param error: é”™è¯¯ä¿¡æ¯
	:param logger: æ—¥å¿—å¯¹è±¡
	"""
	is_running_field = f"is_running_{task_key}"
	is_done_field = f"is_done_{task_key}"
	status_field = f"status_{task_key}"
	error_field = f"last_{task_key}_error"
	heartbeat_field = f"{task_key}_last_heartbeat"

	setattr(doc, is_running_field, 0)
	setattr(doc, is_done_field, 0)
	setattr(doc, status_field, "Failed")
	setattr(doc, heartbeat_field, now_datetime())  # æ›´æ–°å¿ƒè·³æ—¶é—´

	error_msg = error or "è¿è¡Œå¤±è´¥"
	if hasattr(doc, error_field):
		setattr(doc, error_field, error_msg)

	doc.save()
	logger.error(f"[{task_key}] ä»»åŠ¡å¤±è´¥: {doc.doctype}.{doc.name}, error={error_msg}")


@frappe.whitelist()
def cancel_task(docname: str, task_key: str, doctype: str):
	"""
	ç”¨æˆ·å¼ºåˆ¶ç»ˆæ­¢ä»»åŠ¡ï¼ˆå‰ç«¯ç‚¹å‡»å–æ¶ˆæŒ‰é’®è§¦å‘ï¼‰
	:param docname: æ–‡æ¡£åç§°
	:param task_key: ä»»åŠ¡é”®å
	:param doctype: æ–‡æ¡£ç±»å‹åç§°ï¼ˆå¦‚ "Patent Workflow"ï¼‰
	"""
	doc = frappe.get_doc(doctype, docname)
	is_running_field = f"is_running_{task_key}"
	if getattr(doc, is_running_field, 0) != 1:
		return {"success": False, "message": "ä»»åŠ¡æœªå¤„äºè¿è¡ŒçŠ¶æ€ï¼Œæ— æ³•å–æ¶ˆ"}

	fail_task_fields(doc, task_key, "ä»»åŠ¡è¢«ç”¨æˆ·å¼ºåˆ¶ç»ˆæ­¢")
	frappe.db.commit()

	# å¹¿æ’­å®æ—¶å¤±è´¥äº‹ä»¶
	frappe.publish_realtime(
		f"{task_key}_failed", {"docname": docname, "doctype": doctype, "error": "ä»»åŠ¡è¢«ç”¨æˆ·å¼ºåˆ¶ç»ˆæ­¢"}
	)

	return {"success": True, "message": f"{task_key} å·²è¢«ç»ˆæ­¢"}


# @frappe.whitelist()
# def reset_task_status(docname: str, task_key: str, doctype: str):
# 	"""
# 	æ‰‹åŠ¨é‡ç½®ä»»åŠ¡çŠ¶æ€ï¼ˆç”¨äºç”¨æˆ·åœ¨ç•Œé¢ç‚¹å‡»é‡ç½®æŒ‰é’®ï¼‰
# 	:param docname: æ–‡æ¡£åç§°
# 	:param task_key: ä»»åŠ¡é”®å
# 	:param doctype: æ–‡æ¡£ç±»å‹åç§°ï¼ˆå¦‚ "Patent Workflow"ï¼‰
# 	"""
# 	doc = frappe.get_doc(doctype, docname)
# 	fail_task_fields(doc, task_key, error="ç”¨æˆ·æ‰‹åŠ¨é‡ç½®ä»»åŠ¡çŠ¶æ€")
# 	frappe.db.commit()
# 	return {"success": True, "message": f"ä»»åŠ¡ {task_key} çŠ¶æ€å·²é‡ç½®ä¸º Failed"}


# @frappe.whitelist()
# def update_heartbeat(docname: str, task_key: str, doctype: str):
# 	"""
# 	æ‰‹åŠ¨æ›´æ–°ä»»åŠ¡å¿ƒè·³æ—¶é—´ï¼ˆä¾›é•¿æ—¶é—´è¿è¡Œçš„APIè°ƒç”¨ï¼‰
# 	æ³¨æ„ï¼šé€šå¸¸ä¸éœ€è¦æ‰‹åŠ¨è°ƒç”¨ï¼Œä½¿ç”¨ @with_heartbeat è£…é¥°å™¨å³å¯è‡ªåŠ¨å¤„ç†
# 	:param docname: æ–‡æ¡£åç§°
# 	:param task_key: ä»»åŠ¡é”®å
# 	:param doctype: æ–‡æ¡£ç±»å‹åç§°ï¼ˆå¦‚ "Patent Workflow"ï¼‰
# 	"""
# 	try:
# 		doc = frappe.get_doc(doctype, docname)
# 		is_running_field = f"is_running_{task_key}"
# 		# åªæœ‰è¿è¡Œä¸­çš„ä»»åŠ¡æ‰èƒ½æ›´æ–°å¿ƒè·³
# 		if getattr(doc, is_running_field, 0) != 1:
# 			return {"success": False, "message": "ä»»åŠ¡æœªå¤„äºè¿è¡ŒçŠ¶æ€"}
# 		update_task_heartbeat(doc, task_key)
# 		frappe.db.commit()
# 		heartbeat_timeout = TASK_TIMEOUTS.get(task_key, 300)
# 		return {
# 			"success": True,
# 			"message": f"ä»»åŠ¡ {task_key} å¿ƒè·³å·²æ›´æ–°",
# 			"doctype": doctype,
# 			"heartbeat_timeout": heartbeat_timeout,
# 			"recommended_interval": HEARTBEAT_INTERVAL,
# 		}
# 	except Exception as e:
# 		logger.error(f"æ›´æ–°å¿ƒè·³å¤±è´¥: {e!s}")
# 		return {"success": False, "message": f"æ›´æ–°å¿ƒè·³å¤±è´¥: {e!s}"}


# @frappe.whitelist()
# def get_heartbeat_config(task_key: str = None):
# 	"""
# 	è·å–å¿ƒè·³é…ç½®ä¿¡æ¯ï¼Œä¾›å‰ç«¯æˆ–APIè°ƒç”¨æ–¹å‚è€ƒ
# 	:param task_key: ä»»åŠ¡é”®åï¼Œå¯é€‰
# 	"""
# 	if task_key:
# 		return {
# 			"task_key": task_key,
# 			"heartbeat_timeout": TASK_TIMEOUTS.get(task_key, 300),
# 			"recommended_interval": HEARTBEAT_INTERVAL,
# 			"max_safe_interval": TASK_TIMEOUTS.get(task_key, 300) - 60,  # ç•™60ç§’ç¼“å†²
# 		}
# 	else:
# 		return {
# 			"all_timeouts": TASK_TIMEOUTS,
# 			"recommended_interval": HEARTBEAT_INTERVAL,
# 			"description": "å»ºè®®é•¿æ—¶é—´ä»»åŠ¡ä½¿ç”¨ @with_heartbeat è£…é¥°å™¨è‡ªåŠ¨å¤„ç†å¿ƒè·³æ›´æ–°",
# 		}
